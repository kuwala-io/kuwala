{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Popularity Correlation\n",
    "\n",
    "With this notebook you can correlate any value associated with a geo-reference with the Google popularity score. You\n",
    "can upload your own file as a CSV. The only thing that is necessary to make it work is to have columns for latitude and\n",
    "longitude and column headers.\n",
    "\n",
    "The value columns can be specific to your use case, e.g., scooter bookings, sales in shops or crimes. The popularity\n",
    "score is aggregated on a week. So ideally, the value columns that you want to correlate are aggregated on a weekly\n",
    "timeframe as well.\n",
    "\n",
    "As an example we are using an open data set from Uber that gives us the traversals of rides through specific hexagons.\n",
    "You can find the raw data on [their open data platform](https://movement.uber.com/?lang=en-US). We preprocessed the raw\n",
    "data so that the traversals are already aggregated per week.\n",
    "\n",
    "## 1. Set Parameters\n",
    "\n",
    "1. Set the file path to your CSV and the delimiter. Simply place your file under `kuwala/resources` from within the\n",
    "Jupyter environment or under `kuwala/common/jupyter/resources` from the repository root on your local file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_path = '../resources/lisbon_uber_traversals.csv'\n",
    "delimiter = ';'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Set the H3 resolution to aggregate the results on.\n",
    "\n",
    "    To see the average size of a hexagon at a given resolution go to the\n",
    "    [official H3 documentation](https://h3geo.org/docs/core-library/restable). The currently set resolution 8 has on\n",
    "    average an edge length of 0.46 km which can be freely interpreted as a radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resolution = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Set the column names for the coordinates and the columns of the file you want to correlate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lat_column = 'latitude'\n",
    "lng_column = 'longitude'\n",
    "value_columns = ['weekly_traversals']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. You can provide polygon coordinates as a GeoJSON-conform array to select a subregion. Otherwise, data form the entire\n",
    "database will be analyzed. (The default coordinates are a rough representation of Lisbon, Portugal.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "polygon_coords = '[[[-9.092559814453125,38.794500078219826],[-9.164314270019531,38.793429729760994],[-9.217529296875,38.76666579487878],[-9.216842651367188,38.68792166352608],[-9.12139892578125,38.70399894245585],[-9.0911865234375,38.74551518488265],[-9.092559814453125,38.794500078219826]]]'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load dataframes\n",
    "\n",
    "#### Create a Spark session that is used to load your file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kuwala.modules.common import get_spark_session\n",
    "\n",
    "sp = get_spark_session(memory_in_gb=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from geojson import Polygon\n",
    "from kuwala.modules.common import add_h3_index_column, polyfill_polygon\n",
    "\n",
    "df_file = sp.read.option('delimiter', delimiter).csv(file_path, header=True)\n",
    "df_file = add_h3_index_column(df=df_file, lat_column=lat_column, lng_column=lng_column, resolution=resolution)\n",
    "\n",
    "if polygon_coords:\n",
    "    polygon_coords_json = json.loads(polygon_coords)\n",
    "    polygon = Polygon(polygon_coords_json)\n",
    "    h3_index_in_polygon = list(polyfill_polygon(polygon=polygon, resolution=resolution))\n",
    "    df_file = df_file.filter(df_file.h3_index.isin(h3_index_in_polygon))\n",
    "\n",
    "aggregations = { x: 'sum' for x in value_columns}\n",
    "df_file = df_file.select('h3_index', *value_columns).groupBy('h3_index').agg(aggregations)\n",
    "\n",
    "df_file.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Get weekly popularity per hexagon\n",
    "\n",
    "##### Initialize dbt controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from kuwala.modules.common import get_dbt_controller\n",
    "\n",
    "dbt_controller = get_dbt_controller()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run dbt macro to get the aggregated popularity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from kuwala.modules.poi_controller import get_popularity_in_polygon\n",
    "\n",
    "popularity = get_popularity_in_polygon(dbt_controller=dbt_controller, resolution=resolution, polygon_coords=polygon_coords)\n",
    "\n",
    "popularity.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Join dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "popularity = sp.createDataFrame(popularity)\n",
    "popularity = popularity.withColumnRenamed('h3_index', 'join_h3_index')\n",
    "result = df_file \\\n",
    "    .join(popularity, df_file.h3_index == popularity.join_h3_index, 'left') \\\n",
    "    .drop('join_h3_index') \\\n",
    "    .fillna(0, subset=['popularity'])\n",
    "\n",
    "result.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Results\n",
    "\n",
    "#### Pandas Profiling Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "result_pd = result.toPandas()\n",
    "profile = ProfileReport(result_pd, title=\"Pandas Profiling Report\", explorative=True)\n",
    "\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from unfolded.map_sdk import UnfoldedMap\n",
    "from sidecar import Sidecar\n",
    "from uuid import uuid4\n",
    "\n",
    "unfolded_map = UnfoldedMap()\n",
    "sc = Sidecar(title=f'Popularity Correlation', anchor='split-right')\n",
    "\n",
    "with sc:\n",
    "    display(unfolded_map)\n",
    "\n",
    "dataset_id_combined=uuid4()\n",
    "\n",
    "unfolded_map.add_dataset({\n",
    "    'uuid': dataset_id_combined,\n",
    "    'label': f'Correlated values',\n",
    "    'data': result_pd\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}